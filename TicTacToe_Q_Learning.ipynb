{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Dict, List\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "WEpB-Bo9POHF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PGvL7WxKh-Kg"
      },
      "outputs": [],
      "source": [
        "EMPTY, X, O = 0, 1, -1\n",
        "StateType = Tuple[int, ...]\n",
        "ActionType = int\n",
        "QTable = Dict[Tuple[StateType, ActionType], float]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_winner(state: StateType):\n",
        "    wins = [(0,1,2), (3,4,5), (6,7,8),\n",
        "            (0,3,6), (1,4,7), (2,5,8),\n",
        "            (0,4,8), (2,4,6)]\n",
        "    for i,j,k in wins:\n",
        "        if state[i] == state[j] == state[k] != EMPTY:\n",
        "            return state[i]\n",
        "    return None\n",
        "\n",
        "def get_available_actions(state: StateType) -> List[int]:\n",
        "    return [i for i in range(9) if state[i] == EMPTY]\n",
        "\n",
        "def choose_action(state: StateType, Q: QTable, epsilon: float) -> int:\n",
        "    actions = get_available_actions(state)\n",
        "    if np.random.rand() < epsilon:\n",
        "        return int(np.random.choice(actions))\n",
        "    # greedy\n",
        "    best_a, best_q = actions[0], -np.inf\n",
        "    for a in actions:\n",
        "        q = Q.get((state, a), 0.0)\n",
        "        if q > best_q:\n",
        "            best_q, best_a = q, a\n",
        "    return best_a\n",
        "\n",
        "def make_a_move(state: StateType, action: ActionType, player: int) -> StateType:\n",
        "    s = list(state)\n",
        "    s[action] = player\n",
        "    return tuple(s)\n",
        "\n",
        "def iteration(ITERS=200000, alpha=0.1, gamma=0.9, epsilon=0.1):\n",
        "    Q1: QTable = {}\n",
        "    Q2: QTable = {}\n",
        "    for _ in range(ITERS):\n",
        "        state: StateType = tuple([EMPTY]*9)\n",
        "        player = X\n",
        "        while True:\n",
        "            if player == X:\n",
        "                action = choose_action(state, Q1, epsilon)\n",
        "                next_state = make_a_move(state, action, X)\n",
        "                winner = check_winner(next_state)\n",
        "                if winner == X: reward = 1.0\n",
        "                elif winner == O: reward = -1.0\n",
        "                elif winner is None and not get_available_actions(next_state): reward = 0.5\n",
        "                else: reward = 0.0\n",
        "\n",
        "                max_next_q = 0.0\n",
        "                if winner is None and get_available_actions(next_state):\n",
        "                    max_next_q = max(Q1.get((next_state, a), 0.0) for a in get_available_actions(next_state))\n",
        "                old = Q1.get((state, action), 0.0)\n",
        "                Q1[(state, action)] = old + alpha*(reward + gamma*max_next_q - old)\n",
        "\n",
        "            else:\n",
        "                action = choose_action(state, Q2, epsilon)\n",
        "                next_state = make_a_move(state, action, O)\n",
        "                winner = check_winner(next_state)\n",
        "                if winner == O: reward = 1.0\n",
        "                elif winner == X: reward = -1.0\n",
        "                elif winner is None and not get_available_actions(next_state): reward = 0.5\n",
        "                else: reward = 0.0\n",
        "\n",
        "                max_next_q = 0.0\n",
        "                if winner is None and get_available_actions(next_state):\n",
        "                    max_next_q = max(Q2.get((next_state, a), 0.0) for a in get_available_actions(next_state))\n",
        "                old = Q2.get((state, action), 0.0)\n",
        "                Q2[(state, action)] = old + alpha*(reward + gamma*max_next_q - old)\n",
        "\n",
        "            state = next_state\n",
        "            if check_winner(state) is not None or not get_available_actions(state):\n",
        "                break\n",
        "            player *= -1\n",
        "    return Q1, Q2"
      ],
      "metadata": {
        "id": "gYtNKLOMRv63"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1, Q2 = iteration(ITERS = 200000)"
      ],
      "metadata": {
        "id": "mctelTCdjTQE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd6fe2eb"
      },
      "source": [
        "def simulate_game(Q1: QTable, Q2: QTable,\n",
        "                  mode=\"agent_vs_random\", agent_player=X, epsilon=0.0):\n",
        "    state: StateType = tuple([EMPTY]*9)\n",
        "    player = X\n",
        "    while True:\n",
        "        if mode == \"agent_vs_random\":\n",
        "            if player == agent_player:\n",
        "                Q = Q1 if agent_player == X else Q2\n",
        "                action = choose_action(state, Q, epsilon)\n",
        "            else:\n",
        "                action = int(np.random.choice(get_available_actions(state)))\n",
        "        elif mode == \"Q1_vs_Q2\":\n",
        "            Q = Q1 if player == X else Q2\n",
        "            action = choose_action(state, Q, epsilon)\n",
        "        else:\n",
        "            raise ValueError(\"mode must be 'agent_vs_random' or 'Q1_vs_Q2'\")\n",
        "\n",
        "        state = make_a_move(state, action, player)\n",
        "        winner = check_winner(state)\n",
        "        if winner is not None or not get_available_actions(state):\n",
        "            return winner  # X, O, or None\n",
        "        player *= -1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf25666d"
      },
      "source": [
        "def get_statistics(Q1, Q2, num_games=1000):\n",
        "    results = {X: 0, O: 0, None: 0} # None for draws\n",
        "    for _ in range(num_games):\n",
        "        winner = simulate_game(Q1, Q2, mode=\"agent_vs_random\", agent_player=X)\n",
        "        results[winner] += 1\n",
        "    return results"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0777e5bb",
        "outputId": "902789ff-eed6-4202-dbb1-42b6cfe34d53"
      },
      "source": [
        "# Assuming Q1 and Q2 are already trained from the previous step\n",
        "game_stats = get_statistics(Q1, Q2, num_games=1000)\n",
        "print(\"Game Statistics (1000 games):\")\n",
        "print(f\"Player X wins: {game_stats[X]}\")\n",
        "print(f\"Player O wins: {game_stats[O]}\")\n",
        "print(f\"Draws: {game_stats[None]}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Game Statistics (1000 games):\n",
            "Player X wins: 860\n",
            "Player O wins: 117\n",
            "Draws: 23\n"
          ]
        }
      ]
    }
  ]
}